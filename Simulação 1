!pip install translate
!pip install opencv-python numpy tensorflow speechrecognition pygame pillow
import requests
from io import BytesIO
from translate import Translator
import sys


# %% [markdown]
# # ü§ñ Simulador de Bra√ßo Rob√≥tico com IA
# > Projeto de TCC - Engenharia Mec√¢nica
# > *Reconhecimento de objetos por voz + vis√£o computacional*

# %% [markdown]
# ## 1. Configura√ß√£o do Ambiente
# Instala√ß√£o das bibliotecas necess√°rias:


# %% [markdown]
# ## 2. M√≥dulo de Vis√£o Computacional (Simulado)
# Usaremos imagens de exemplo ou sua webcam:

# %%
import cv2
import numpy as np
from IPython.display import display, Image, clear_output
import ipywidgets as widgets

# Escolha o modo de simula√ß√£o
mode = widgets.Dropdown(
    options=['Webcam', 'Imagem de Exemplo'],
    value='Imagem de Exemplo',
    description='Fonte de Imagem:'
)
display(mode)

Link_Imagem = input("Digite o link da imagem: ")
url = Link_Imagem

# %%
def simulate_camera():
    if mode.value == 'Webcam':
        # Captura da webcam
        cap = cv2.VideoCapture(0)
        ret, frame = cap.read()
        cap.release()
        return frame
    else:
        # Imagem de exemplo (garrafa)
        response = requests.get(url)
        if response.status_code != 200:
            raise ValueError(f"Erro ao acessar a URL (status: {response.status_code})")
        img_bytes = BytesIO(response.content)
        img_array = np.asarray(bytearray(img_bytes.read()), dtype=np.uint8)
        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)
        return img

# Mostra a imagem capturada
img = simulate_camera()
cv2.imwrite('captured.jpg', img)
display(Image('captured.jpg', width=300))

# %% [markdown]
# ## 3. Reconhecimento de Objetos com IA

# %%
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions

# Carrega o modelo pr√©-treinado
model = MobileNetV2(weights='imagenet')

# Pr√©-processamento da imagem
img_processed = cv2.resize(img, (224, 224))
x = image.img_to_array(img_processed)
x = np.expand_dims(x, axis=0)
x = preprocess_input(x)

# Predi√ß√£o
preds = model.predict(x)
results = decode_predictions(preds, top=3)[0]

translator = Translator(to_lang="pt")


print("üîç Objeto reconhecido:")
for i, (_, name, prob) in enumerate(results):
    nome_pt = translator.translate(name)
    print(f"{i+1}. {nome_pt} ({prob*100:.2f}%)")
    nome1_pt = translator.translate(results[0][1])
# %% [markdown]
# ## 4. M√≥dulo de Voz (Simulado)

# %%
import speech_recognition as sr
import pygame

# Configura√ß√£o do simulador de voz
print("üé§ Simulador de Comando de Voz")
print("Op√ß√µes v√°lidas: 'O que √© esse item' ou 'Sair'")

# Simulando o comando (no Colab usamos input)
comando = input("Digite o comando de voz: ").lower()

if "o que √© esse item" in comando:
    print("ü§ñ Bra√ßo movendo para posi√ß√£o de an√°lise...")
    print(f"‚úÖ Resultado: {nome1_pt}")
elif "sair" in comando:
    print("üî¥ Encerrando sistema...")
    sys.exit()
else:
    print("‚ö†Ô∏è Comando n√£o reconhecido")

# %% [markdown]
# ## 5. Simula√ß√£o do Bra√ßo Rob√≥tico

# %%
# Simula√ß√£o gr√°fica simples
print("\nSimula√ß√£o do movimento do bra√ßo:")

# ASCII Art do bra√ßo
print("""
       ‚Üë
       |
   ----+----
  /    |    \\
 /     |     \\
/      |      \\
""")

print(f"Posicionando para analisar: {results[0][1]}")
print("""
       ‚áß
       |
   ----+----
  /    ‚á©    \\
 /     ‚á©     \\
/      ‚á©      \\
""")

# %% [markdown]
# ## 6. Integra√ß√£o Completa (Simulada)

# %%
class SistemaRobo:
    def __init__(self):
        self.banco_dados = {
            'water_bottle': 'Garrafa de √Ågua',
            'keyboard': 'Teclado'
        }

    def processar_comando(self, comando):
        if "o que √© esse item" in comando:
            # Simula vis√£o computacional
            img = simulate_camera()
            obj = results[0][1]
            obj_pt = translator.translate(obj)

            # Verifica no banco de dados simulado
            nome = self.banco_dados.get(obj, None)

            if nome:
                print(f"‚úÖ Objeto reconhecido: {nome1_pt}")
            else:
                print(f"üîç Objeto n√£o cadastrado. Adicionando '{obj_pt}' ao banco...")
                self.banco_dados[obj] = obj
                print(f"üìù Novo objeto aprendido: {obj_pt}")

            # Simula movimento
            print("\nMovimento do bra√ßo:")
            print("""
            Posi√ß√£o Inicial ‚Üí Posi√ß√£o de An√°lise
                  ‚á©
               [=====]
              /  ‚áß  \\
             /   ‚áß   \\
            /    ‚áß    \\
            """)

            return nome1_pt or obj_pt

# Teste
robo = SistemaRobo()
robo.processar_comando("o que √© esse item")
